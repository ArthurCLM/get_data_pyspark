{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The principal objective of this code it's comparing the time of programing between use a regular query to a pyspark query. The table is locate in a remote database and it has more than 10 million registers. As i'm said, the whole objective its only comparing the mtime of programing and don't know about the results of the table it self.\n",
        "\n",
        "All the codes were running in google colab."
      ],
      "metadata": {
        "id": "BGGNY0uE-IYw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OGzhCuwfSvl6"
      },
      "outputs": [],
      "source": [
        "import psycopg2 as pg\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "def get_data(host, database, user, password, query):\n",
        "\n",
        "  # get the start time\n",
        "  st = time.time()\n",
        "  try:\n",
        "      connection = pg.connect(host = host, database = database, user = user, password = password)\n",
        "      #Applying the query\n",
        "      df = pd.read_sql(query, connection)  \n",
        "\n",
        "  except (Exception, pg.Error) as error:\n",
        "      print(\"Error while fetching data from PostgreSQL\", error)\n",
        "\n",
        "  finally:\n",
        "      # closing database connection.\n",
        "      if connection:\n",
        "          connection.close()\n",
        "          print(\"PostgreSQL connection is closed\")\n",
        "\n",
        "  # get the end time\n",
        "  et = time.time()\n",
        "\n",
        "  # get the execution time\n",
        "  elapsed_time = et - st\n",
        "  if(elapsed_time > 60): \n",
        "    elapsed_time = elapsed_time/60\n",
        "    message = 'minute(s)'\n",
        "  else:\n",
        "    message = 'second(s)'\n",
        "\n",
        "  print('#######################################################')\n",
        "  print('Execution time:', round(elapsed_time, 2), message)\n",
        "  print('#######################################################')\n",
        "\n",
        "  return df\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Connecting to a simple database using the function get_data, all the credentials is confidential\n",
        "host = 'host'\n",
        "database = 'database'\n",
        "user = 'user'\n",
        "password = 'password'\n",
        "query = 'SELECT * FROM \"table\"'\n",
        "\n",
        "df = get_data(host, database, user, password, query)"
      ],
      "metadata": {
        "id": "y3ezfIjw_qYU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14719b28-19e2-4e54-8b00-8ef00ecadadd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PostgreSQL connection is closed\n",
            "#######################################################\n",
            "Execution time: 3.27 minute(s)\n",
            "#######################################################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Showing the number of rows\n",
        "len(df.index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CG8umVjEtkEb",
        "outputId": "ccaa6cf0-98f1-417a-9b52-42189fd73a73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11054769"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Construing the pyspark structure"
      ],
      "metadata": {
        "id": "WNUuUvMGEPeW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# installing the dependencies\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "#Intalling postgres drive for spark\n",
        "!wget https://jdbc.postgresql.org/download/postgresql-42.2.16.jar"
      ],
      "metadata": {
        "id": "HmE5pUAit2hl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7a828d7-5e0c-4eb2-b344-67158c0dc7c8"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-30 01:54:45--  https://jdbc.postgresql.org/download/postgresql-42.2.16.jar\n",
            "Resolving jdbc.postgresql.org (jdbc.postgresql.org)... 72.32.157.228, 2001:4800:3e1:1::228\n",
            "Connecting to jdbc.postgresql.org (jdbc.postgresql.org)|72.32.157.228|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1002883 (979K) [application/java-archive]\n",
            "Saving to: ‘postgresql-42.2.16.jar.2’\n",
            "\n",
            "postgresql-42.2.16. 100%[===================>] 979.38K  5.08MB/s    in 0.2s    \n",
            "\n",
            "2022-09-30 01:54:45 (5.08 MB/s) - ‘postgresql-42.2.16.jar.2’ saved [1002883/1002883]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure environment variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\" \n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\"\n",
        "\n",
        "# Make pyspark \"importable\"\n",
        "import findspark\n",
        "findspark.init('spark-2.4.4-bin-hadoop2.7')"
      ],
      "metadata": {
        "id": "AEB5mOV9u0AY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"CloudETL\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.16.jar\").getOrCreate()"
      ],
      "metadata": {
        "id": "RMj24XMOEvv7"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "# get the start time\n",
        "st = time.time()\n",
        "\n",
        "df = spark.read \\\n",
        "    .format(\"jdbc\") \\\n",
        "    .option(\"url\", \"jdbc:postgresql://host:port/database\") \\\n",
        "    .option(\"dbtable\", \"dbtable\") \\\n",
        "    .option(\"user\", \"user\") \\\n",
        "    .option(\"password\", \"password\") \\\n",
        "    .option(\"driver\", \"org.postgresql.Driver\") \\\n",
        "    .load()\n",
        "\n",
        "  # get the end time\n",
        "et = time.time()\n",
        "\n",
        "  # get the execution time\n",
        "elapsed_time = et - st\n",
        "if(elapsed_time > 60): \n",
        "    elapsed_time = elapsed_time/60\n",
        "    message = 'minute(s)'\n",
        "else:\n",
        "    message = 'second(s)'\n",
        "\n",
        "print('#######################################################')\n",
        "print('Execution time:', round(elapsed_time, 2), message)\n",
        "print('#######################################################')    "
      ],
      "metadata": {
        "id": "rHUkQyFrskh1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "520d0191-aaa1-41dc-897d-9170ef02e23d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#######################################################\n",
            "Execution time: 0.52 second(s)\n",
            "#######################################################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(df)"
      ],
      "metadata": {
        "id": "D3qJlCJJIPUp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
